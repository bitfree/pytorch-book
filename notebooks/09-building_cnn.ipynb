{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 합성곱 네트워크 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "# 3.2.8 장에서 정의한 훈련 및 테스트 함수를 불러온다.\n",
    "from train_utils import train, test, main\n",
    "# 시각화를 위한 matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 살펴보기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Number of Traing Set 50000, Test Set 10000\n",
      "\n",
      "Target: car\n",
      "Size of Image: torch.Size([3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFdJJREFUeJztnclvHWd2xW+NbyLfwEHiJErUYEu25Vnpdrtt95Bu2L3oZTaN/hsCZJFllklnnSyCANllE6CBAAkQBO7ATsd2x7Fla7AkyxJNUhQpio/Dm8easgiy+84HKIsXqO/5Lb+Dj69eVZ1XQB3ee50sy4QQ8vuP+/99AISQyUCzE6IEmp0QJdDshCiBZidECTQ7IUrwJ/lhf/XrP4M5X5KewRv9gXH57jef4S3+HNTOnMCf9cKzl6HWGn1jXO8MGnBPnG5DrTTVxp/VTqE2MzULtUJYMa7vH9Xhnof7x1C7fXMHap4bQq02d8a4/uZra3BPvlSCWhbOQK1+uA61hw+bxvVOKwf3tI/w+ahMl6HmeXhft4vvka+ubxrXO00P7nnnhz+H2t/9+a8c0zqf7IQogWYnRAk0OyFKoNkJUQLNTogSaHZClDDR6O3u+tdQC4IEaqtrJ817PBxNjIc41gqDIdTiGMcnUXxoXB+NcLyWRjhyWd97DLXDRgy186tdqFXKReP69i7eM4hqUAv8Z6BWq52DWhFEVON0Ee6J+/g4Oo081JrHOIoMwB1ereFbv1LsQe1w/z7UPNccEYuIDHv4Pui1zdd6fnYF7rl583OoIfhkJ0QJNDshSqDZCVECzU6IEmh2QpRAsxOihIlGbxcu/AJqw0EAtemcOU4q543FPSIisrm3AbUtpw81V8xVUiIiYc0c9WXONNyTSAdqBw0c1TQOR1CL5qegNi6YjyUoXoF7pkpvQK1YM597EZEoxs+KLDVrm/Ux3CMOvp6lEr4/IsEVcb2x+fPGYF1EpN+MoJZ5+NwfW+LSXgtf6zBv/m7jFMfAxRK+Lgg+2QlRAs1OiBJodkKUQLMTogSanRAlTPRtfOLh/m6u14LatavmAppPPr4B97Q6lkIY9xHU8vm7UJtbMb+JPX3mBNxz+vQpqGViLqwREUmSLajtH+K3xe34WeN6Ye49fBwhLiQZjPF57A1wquFl5h56QYjHjfkZfkP+5uu4IMfB7fqk1TH/zf1DnLq8/z6+P/ygALVSFRfyZCkuhKnNmc9xu4v7BhbL+J5D8MlOiBJodkKUQLMTogSanRAl0OyEKIFmJ0QJE43edvdxz7XhMR4z9NHHHxjX64e7cE8Q4EKBOMVFFa0G7j/Wd8z7dg/34Z71dXwca2fxKKRcARfCdJNXoFapmSM2dwpHNZ0e7k+XJrhfXy6HCz/GXbPWtcR1vov7EP7rb65CrVjEx5Gk5lxuF4yFEhEZtCyx7fQB1KYq+H6MU3yOTy6bR3ad9HGm6FnOFYJPdkKUQLMTogSanRAl0OyEKIFmJ0QJNDshSpho9CaWUUgP7uNqswMQbQU+HgmUJri6CiRoIiLi5/EpWVoFVU2lEtzTquPeY5ub+Lf28utvQW313M+hFlbnjevjBEeKmSVecz1cieakWGuDqsMCLhoTP8Ta7U0cby4u4I1ZYo7l7q7jkV1TLu4p6AyP8GeVcCyXxThGyxLz/VOZqcI9oy6+Zgg+2QlRAs1OiBJodkKUQLMTogSanRAl0OyEKGGi0duwhcfZbN67BzXfM0dsxfIc3NO1NJzMBI8ZMg94+h8e75hjF0u/RpmdwaOJ0iGu1qqd/BnUbBVsSWr+3pU8jqf6Dj4OyePnQbeH98WROfpsxZZqvj7+e66Do9TBAMda7ab5fMS2KCyHtYMDHKUWPBzZ5QXfq42H5mN0QSQnIpILOf6JEAKg2QlRAs1OiBJodkKUQLMTogSanRAlTDR629vClUbHluaRl55/0bjuhubZayIi3/Zxg78sxNVyvovjny6IcZ5ZPgf3XFpdhZpXxLPBynMrUBunOL4qgUrAfgtXvUWWuWe2+Wu5bgdqTgtUOFqyzUIZX5dqDcdQoxE+xmHb3OAybzmOOMKz9LIBjtf8EY4369t4lmG7Yz5XseDYNkpxfIzgk50QJdDshCiBZidECTQ7IUqg2QlRwkTfxl///BrUsgSPBXqw/pVxvd/Db03dEq5OKRTLUBuN8JvueGx+Ux9EeBTPchknBu0RfkO+deM/oba0jN/wu2Xza+ajxzgJeXwfJyFOarlFYnz8O/fWjetBETehq128CLXAx/s6Xfw2PszMb8jjDKcujuAik6iDX+Pf/PwO1BqHh1ArzZibIpYDXPBUCnE6geCTnRAl0OyEKIFmJ0QJNDshSqDZCVECzU6IEiYavbVbuBggifA4m0HHHK24AY61ggD3LPMtUc3c3GmorV5aNK7Pz+OChU8tcUyriUca9SNc6BDmLP3HEvDdLCOexoJjrcVzb0DtmQuvQe3tZ//QuB5n+Lq4rqU6xcHx5lTN0p+ub/7e9Tq+Fx9s4Siy2cQRWjGHz+OZS+eh5oI4Mknx+bh8rgI1+DlPvIMQ8lRCsxOiBJqdECXQ7IQogWYnRAk0OyFKmGj0lgmOSMYRPpQwZ+7VVp3HfdpOr+HKsEsv4shoeQX3kzu9tmRcdwIck926tQy1OMK/tYnl0qSW3+jRwFzNlca4QjDBqZZUZ3Dl1exJrI1QJWCCj6NQwNWIIpYRT5axYvsg3txv4lhrd6cOtZKlinFlBR+/E+K4d5yYr3Vg+c6hpVcigk92QpRAsxOiBJqdECXQ7IQogWYnRAk0OyFKmGj0liY4oirP4KqgF179rnH9O2+a10VEzp7FkVd5bgFqkS3y8s3HP07wb+b5V96GWn+Ao8j+CMcuUWTRYnPkNRjifO14/wBq9x+YG0eKiGzsHkGt3TGPysoXcOS1vHIJap02Huf1YOM+1AZDc9SX+fgcxjGOtQpl3OjR83HT1G4bj8oqT1eN69/7A/PYMxGRdIj/HoJPdkKUQLMTogSanRAl0OyEKIFmJ0QJNDshSpho9PbyG29C7Xs//inUzoIZYNPTuAJJPPOMLxGRjiW6avVw7HLUMM+Ba3fxnkEfVzt1+7gCbDzGWmopU0NNGz3L+UgTS3VVGVcWhgXc+LI4a44pPcuMtf16E2oPNr6F2vERrnqbmjLfI3MVy72zOA+lQvQIapllTuBUHlcIRj3z9fz4g1twj5dYorc/MS/zyU6IEmh2QpRAsxOiBJqdECXQ7IQogWYnRAkTjd7++E9BJiAi01U8u2o4MkcTcYKrxvYtkdfOIZ57trVtrtYSEWm2zXHYoI8jlyQeQC0M8OnPhbg6rDQ9DbVCAZxHy9ywIMBa6OWglma4ijGLzOe/ffgY7tl9sAe1ThdXlLkhnrE2SszXpgOupYiI4+EIcNrFMWUtjyM7r4Sv2daGubKw38Xx2riHm2Ii+GQnRAk0OyFKoNkJUQLNTogSaHZClDDRt/EvrOE3koGLiztG4KX7p+u4L9nVW/jtbb2JizGKHtbmCmYtV8Vvs08tnoTaYg33M/N9fGl6aQC1JvjaaYyPcRTjt+q9Lk41hn18zfrtnnF901LQ0jjGvfCyFD+XXMu5isbmN+sdsC4islTGicyJyhzUKgVcbFSu4mt2cemycb1WwQnVjZtfQA3BJzshSqDZCVECzU6IEmh2QpRAsxOiBJqdECVMNHrrNvE/7/e6Lah9u2Hu+/VPv8P9wHYbOOooFHHhxHs/Mfe7ExG5fN48pqdYxJ9Vm8ZxTCHARSZiiZNubOMCiRYoGBl38PmtH+F47dH6BtR6PRxvjkB/vZrgPV4Ff6/uOA+1YYYj3XLJ3Guu5OEoMj7cxJ/l4bjx9RevQM0VvC8PCqKqNfP9JiKyuICLbvAxEEJUQLMTogSanRAl0OyEKIFmJ0QJNDshSpho9HZs6fv1F3/5t1D74oN/Ma5nLq7WSl38O1auLkHtVvAjqD38wny6Do5wBVWvb67+EhFZWVqE2sK5F6D27WNcmVfLm+OrhXk87mh5fgFqS1ewdtxsQK1SNEdbC/M4Mjpq4CrGW5s4Onz/Mzz+qQTSzQD0phMRuXf3S6g1i/jcX3nleaj5Po5ny2VzFJxYRmVVZ3Ash+CTnRAl0OyEKIFmJ0QJNDshSqDZCVECzU6IEiYavYmLxzUVpk5Azc+ZK57GPdygMIpxbCElXEH1wYf/BrWDurnKLrZ8lmP5PfVDHMfMLL8BtdIUbkT4yz/6vnG9WsGR1/ERjrX6XRwdjiIcpU4H5kq0Uh5/59nzp6E29nC89o//vgW1fsd8jO5gB+5JIlyZ12xgbW8fn0fXEr1tPjCPxOp28HdeWqpBDR7DE+8ghDyV0OyEKIFmJ0QJNDshSqDZCVECzU6IEiYavVUreLbZuz99D2q5fNG4/rvf/gbvGeCqpiiFkhSmcKTxw5fNM7k8S4Vd8xg3czzs4iqv3TreNz+D99UPzPHg3v423HN0hGebtYf4PF5YOwu1vdQcUc3O4Vlp8/kZqD3a2YVar7EHNQ88z9wBjrU8wVFqlGDtyxtfQ607wjFlMjKfYyfDMV9t5nWoIfhkJ0QJNDshSqDZCVECzU6IEmh2QpQw0bfxjxr4tyU3g3uduYVTxvU0fx7uKc/gsUvFIi4kee21Nai9/JJZqzfxm9Yjy9v4s5aCi+s31qF28SweGzW3bO6vl0VDuKc6i8/9XgePLRpYegCOBubvvfPRHbinP7gLtW82cNGTZPh8VGvm/m7DCL9VD8q4X99xA6cT+4dHUHNDbLVZkFIVAkvxzDYu5IHH8MQ7CCFPJTQ7IUqg2QlRAs1OiBJodkKUQLMTooSJRm9//Tf/ALW24HE27WNzTPLilbfgnre/j/uZzddwP7Yi6HcnItIDBQtejCO0goujN0lxRc53f4CLTE6cxL/RK6uzxvW9jU24Z2/3EGqlhZeg1uviOG/vobkg5/ZXuFik1cY93GzjvObK5u8sIjIamuMwR/B1WVlZgVqzjYuGUsu4pqk8vq9ygXnf9tZ9uCdOzOO1bPDJTogSaHZClECzE6IEmp0QJdDshCiBZidECRON3q5/+M9Q6/dxDDV36oJxPcutwj27d/Hfa07hnmU+6HcnIuKE5mqofBHHKqUC/j11PbwvCHElV2YZG7V7ZL6k93ZwtdbVa1tQe/47r0ItHuOegt3EXFmYL+MKu9pMGWpHddxDr1PfglrSM49WKvm4iq68vAi1IMDXrJDDdioFuEKwvrtlXG81cJ+8kwtnoIbgk50QJdDshCiBZidECTQ7IUqg2QlRAs1OiBImGr2l4wbU4g6uvErb5qaHm1c/gXvWP8MNJ8XD0VXm4FNSnjE3vlw5ax4LJSIySvDv6cERHuNUqOD4J3ZwxVM8MFeOBQ6uyOr1cdXetff/HmpZjP+mmw2M614f3wOFEFfRuT38WV6Mz4frmP+m52T4OErTUKvW8HiwUh7fO4MubkaZZeaY+PQZ3Px0ehqPykLwyU6IEmh2QpRAsxOiBJqdECXQ7IQogWYnRAkTjd5mFk5ALbE0bWw1zJVLWRc3UXQtc8gyB//GZSneNzdtjmsqPo5BGr0m1Da+/BR/1vLbUBMXV/RFbXNDxxcvXYR7ghE+xgfXv4LayRAfR7lgPo+VAFfzBZZI9Ch3DmqLS7i5qIDocyqH57nlLE1HiwVsGUfwPdzv42aahby5ejAH1v/3054UPtkJUQLNTogSaHZClECzE6IEmp0QJUz0bXwxjwsMQs9c7CKC32T6IX5bWcjht74nF5ahVq7gY3zpFXM/tpdevQL33PvmDtS+/PRDqI1HuEdavliA2sWz5lFIa6dxYtDq4zfTvUOceGQD3NcuBm/dBznc42+cw0UmEuDjHycR3paa76tk3IN7kjEuouq2cSFPluHjcCwJkOebUwjfsxRzWQq2EHyyE6IEmp0QJdDshCiBZidECTQ7IUqg2QlRwkSjt3iE+3CNLcUYg4FZCzzLb1Vi64+Gt5WnzdGViEi1Om9cj8e4IKRawpFR6OB4MI7w+QhcHDkuLKwY12cW8dilxkNzoZGISHH+JNTW7+1CLe2PzX+viAs4KrM4Ek0K5nFSIiKDJj5XXmSO2LLeXbinWDKPGxMRiWMcEUuGv1tpCsebYWiOUh0X29P1cN89uOeJdxBCnkpodkKUQLMTogSanRAl0OyEKIFmJ0QJE43enKgNtQuXfwC1h4/NY5KOdu/DPYMU9wP7egtHTdt1vO+za+YKtiTGY4tKIT7F3TaOjMpFHHmFAY5dhuCSLp99Ae4plM2RoohI6/FDqEWje1BD6Wbk4P5uaYCr+frNfbxvbB41JSKSxOZzfGq2DPdMTVuq7yyjt4LQogX4e7uuueotzXBG7DvsQUcIAdDshCiBZidECTQ7IUqg2QlRAs1OiBImGr1llihhYfk81OLAvM/J4bE/tuqqn7yDRyFdvID/5vYjc/xz+85tuOfOzWtQi7vmyjARkc4Aa/kYV9nd3TDHiqv3duCemSl8G9TBdxYRSS0NFlNQ0ef5OOYbjnBFWTTA45NCS/XjCFRT5nO4GrHZ6EBtPMbfOQzx+Ko4tZRaxuYKTd/F38u1eAnueeIdhJCnEpqdECXQ7IQogWYnRAk0OyFKoNkJUcJEo7cIpxby3BqesfbuO0vG9Vvf4Oq19hD/jr312vNQW1nFjRmfe/ll4/qP3v0Z3FPfw8f4aOcB1G7fwRV9t+/gOOzo0Px5v/3oOtxTCHBMuX2A47Bc5RTUnNAcvRVrlqaSMZ6/lsvhuDHq42rKdGiO3o7q+GbsWaoRAx9bxrPMZssEn+MUSFGCv7NElsaXAD7ZCVECzU6IEmh2QpRAsxOiBJqdECXQ7IQoYbJVbwmu5Lp19VOo9farxvXQx7PSHn29AbVf/cevoZbL4wjQzZmbFM4tmKNBEZH5OcvsuBNYq0zh4widA6gVwDEOxrgia4gvi0zN4QpB39L40vfMlVzpCMdr4x6uzOs396A2svxNNzN/uU57hI8jws0hiyU8s821xHKupYLNccyarbAtSRm9EUIANDshSqDZCVECzU6IEmh2QpQw2fFPgt+aXrv2X1D75CPzvswyAadv6VnmgzfWIiK+g09JBHqFjS094VJL7zHPs7zNtiQNYViCmoB+bG6AizR8H799ThL81tdN8fd2EvPb7miI+7uNhg2oZRk+Dt9SyCO+OYWIYnw+ZIz/XqWGE5TAco4dy9t4QUUy4C29dY8FPtkJUQLNTogSaHZClECzE6IEmp0QJdDshChhotGb6+AY6tnn1qC2u/3IuF6vH8I9hdASJ1ma4WUujngC8NPo53AMYhvSYxuHlWUDqMXjLtQc8IkZTj0lFhwBWhMexxK9ge+WWvJS17cch+VE2g4xA5+XWGLDahEXIQWW++r/XAgDnrm2iVGOJbaFx/DEOwghTyU0OyFKoNkJUQLNTogSaHZClECzE6IExxb/EEJ+f+CTnRAl0OyEKIFmJ0QJNDshSqDZCVECzU6IEmh2QpRAsxOiBJqdECXQ7IQogWYnRAk0OyFKoNkJUQLNTogSaHZClECzE6IEmp0QJdDshCiBZidECTQ7IUqg2QlRAs1OiBJodkKU8N9OnwRjZe3t/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code 3.4.1\n",
    "\n",
    "torch.manual_seed(70)\n",
    "# 데이터 셋 불러오기\n",
    "train_dataset = datasets.CIFAR10('./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.CIFAR10('./data', train=False, transform=transforms.ToTensor())\n",
    "# 데이터 개수 알아보기\n",
    "print(\"Number of Traing Set {}, Test Set {}\\n\".format(len(train_dataset), len(test_dataset)))\n",
    "\n",
    "# Cifar 10 데이터는 총 10개 카테고리가 포함된 사물이미지가 있다\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# 랜덤 이미지 살펴보기 \n",
    "idx = torch.randint(0, len(train_dataset), (1,)).item()\n",
    "random_image = train_dataset[idx][0]\n",
    "target_num = train_dataset[idx][1]\n",
    "\n",
    "# 해당하는 사물 카테고리 및 이미지 크기 살펴보기\n",
    "print(\"Target: {}\".format(classes[target_num]))\n",
    "print(\"Size of Image: {}\".format(random_image.size()))\n",
    "# plt.imshow 는 (높이, 넓이, 채널) 형태로 입력을 받아야 출력 가능하다.\n",
    "plt.imshow(random_image.numpy().transpose(1, 2, 0))  \n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경 변수 설정\n",
    "BATCH = 128  # 미니배치크기\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'  # 디바이스\n",
    "STEP = 30  # 총 반복스텝\n",
    "PRINT_STEP = 180  # 경과 print 기간\n",
    "\n",
    "# 데이터로더 선언\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 합성곱 신경망 네트워크 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code 3.4.2\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.flatten = lambda x: x.view(x.size(0), -1)\n",
    "        # Convolution Operation Layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=5, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=2, stride=1, padding=0)\n",
    "        # Activation Layer\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # MaxPool Layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Fully Connect Layer\n",
    "        self.fc = nn.Linear(784, 10)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        ## Convolutional Layer\n",
    "        # input: (batch, 3, 32, 32) \n",
    "        # > conv1: (batch, 8, 30, 30) \n",
    "        # > pool1: (batch, 8, 15, 15)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # > conv2: (batch, 16, 14, 14) \n",
    "        # > pool2: (batch, 16, 7, 7)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        ## Fully Connect Layer\n",
    "        # flatten\n",
    "        x = self.flatten(x)\n",
    "        # input: (batch, 32*6*6) > output: (batch, 10)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code 3.4.2\n",
    "\n",
    "# 모델 선언\n",
    "torch.manual_seed(70)\n",
    "model = CNN().to(DEVICE)\n",
    "# 손실함수 선언\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "# 옵티마이저 선언\n",
    "optimizer = optim.Adam(model.parameters()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 및 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Step: 1 (00.00%)  \tLoss: 2.3060\n",
      "Train Step: 1 (46.08%)  \tLoss: 1.7382\n",
      "Train Step: 1 (92.16%)  \tLoss: 1.5788\n",
      "Test set: Average loss: 1.5836, Accuracy: 4386/10000 (43.86%)\n",
      "\n",
      "Train Step: 2 (00.00%)  \tLoss: 1.5672\n",
      "Train Step: 2 (46.08%)  \tLoss: 1.5628\n",
      "Train Step: 2 (92.16%)  \tLoss: 1.4709\n",
      "Test set: Average loss: 1.4816, Accuracy: 4800/10000 (48.00%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 3 (00.00%)  \tLoss: 1.4164\n",
      "Train Step: 3 (46.08%)  \tLoss: 1.3405\n",
      "Train Step: 3 (92.16%)  \tLoss: 1.4744\n",
      "Test set: Average loss: 1.4257, Accuracy: 4931/10000 (49.31%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 4 (00.00%)  \tLoss: 1.2830\n",
      "Train Step: 4 (46.08%)  \tLoss: 1.4501\n",
      "Train Step: 4 (92.16%)  \tLoss: 1.3419\n",
      "Test set: Average loss: 1.3607, Accuracy: 5182/10000 (51.82%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 5 (00.00%)  \tLoss: 1.4698\n",
      "Train Step: 5 (46.08%)  \tLoss: 1.2773\n",
      "Train Step: 5 (92.16%)  \tLoss: 1.3185\n",
      "Test set: Average loss: 1.3519, Accuracy: 5216/10000 (52.16%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 6 (00.00%)  \tLoss: 1.4237\n",
      "Train Step: 6 (46.08%)  \tLoss: 1.3649\n",
      "Train Step: 6 (92.16%)  \tLoss: 1.1580\n",
      "Test set: Average loss: 1.3085, Accuracy: 5416/10000 (54.16%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 7 (00.00%)  \tLoss: 1.2554\n",
      "Train Step: 7 (46.08%)  \tLoss: 1.3345\n",
      "Train Step: 7 (92.16%)  \tLoss: 1.1727\n",
      "Test set: Average loss: 1.2852, Accuracy: 5445/10000 (54.45%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 8 (00.00%)  \tLoss: 1.2241\n",
      "Train Step: 8 (46.08%)  \tLoss: 1.2540\n",
      "Train Step: 8 (92.16%)  \tLoss: 1.2381\n",
      "Test set: Average loss: 1.2701, Accuracy: 5486/10000 (54.86%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 9 (00.00%)  \tLoss: 1.1989\n",
      "Train Step: 9 (46.08%)  \tLoss: 1.2185\n",
      "Train Step: 9 (92.16%)  \tLoss: 1.2119\n",
      "Test set: Average loss: 1.2345, Accuracy: 5666/10000 (56.66%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 10 (00.00%)  \tLoss: 1.2677\n",
      "Train Step: 10 (46.08%)  \tLoss: 1.1622\n",
      "Train Step: 10 (92.16%)  \tLoss: 1.1720\n",
      "Test set: Average loss: 1.2480, Accuracy: 5633/10000 (56.33%)\n",
      "\n",
      "Train Step: 11 (00.00%)  \tLoss: 1.2836\n",
      "Train Step: 11 (46.08%)  \tLoss: 0.9894\n",
      "Train Step: 11 (92.16%)  \tLoss: 1.2764\n",
      "Test set: Average loss: 1.2009, Accuracy: 5816/10000 (58.16%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 12 (00.00%)  \tLoss: 1.1132\n",
      "Train Step: 12 (46.08%)  \tLoss: 1.2130\n",
      "Train Step: 12 (92.16%)  \tLoss: 1.0355\n",
      "Test set: Average loss: 1.2107, Accuracy: 5740/10000 (57.40%)\n",
      "\n",
      "Train Step: 13 (00.00%)  \tLoss: 1.1460\n",
      "Train Step: 13 (46.08%)  \tLoss: 1.0796\n",
      "Train Step: 13 (92.16%)  \tLoss: 1.4333\n",
      "Test set: Average loss: 1.2010, Accuracy: 5809/10000 (58.09%)\n",
      "\n",
      "Train Step: 14 (00.00%)  \tLoss: 1.0081\n",
      "Train Step: 14 (46.08%)  \tLoss: 1.1248\n",
      "Train Step: 14 (92.16%)  \tLoss: 1.2319\n",
      "Test set: Average loss: 1.2054, Accuracy: 5810/10000 (58.10%)\n",
      "\n",
      "Train Step: 15 (00.00%)  \tLoss: 1.1389\n",
      "Train Step: 15 (46.08%)  \tLoss: 1.0926\n",
      "Train Step: 15 (92.16%)  \tLoss: 1.1895\n",
      "Test set: Average loss: 1.1687, Accuracy: 5898/10000 (58.98%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 16 (00.00%)  \tLoss: 1.1836\n",
      "Train Step: 16 (46.08%)  \tLoss: 1.0755\n",
      "Train Step: 16 (92.16%)  \tLoss: 1.1036\n",
      "Test set: Average loss: 1.1701, Accuracy: 5894/10000 (58.94%)\n",
      "\n",
      "Train Step: 17 (00.00%)  \tLoss: 1.0511\n",
      "Train Step: 17 (46.08%)  \tLoss: 1.2380\n",
      "Train Step: 17 (92.16%)  \tLoss: 1.1182\n",
      "Test set: Average loss: 1.1523, Accuracy: 6010/10000 (60.10%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 18 (00.00%)  \tLoss: 1.0447\n",
      "Train Step: 18 (46.08%)  \tLoss: 1.0559\n",
      "Train Step: 18 (92.16%)  \tLoss: 1.1679\n",
      "Test set: Average loss: 1.1645, Accuracy: 5955/10000 (59.55%)\n",
      "\n",
      "Train Step: 19 (00.00%)  \tLoss: 1.1791\n",
      "Train Step: 19 (46.08%)  \tLoss: 1.1374\n",
      "Train Step: 19 (92.16%)  \tLoss: 1.0825\n",
      "Test set: Average loss: 1.1427, Accuracy: 6016/10000 (60.16%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 20 (00.00%)  \tLoss: 1.0054\n",
      "Train Step: 20 (46.08%)  \tLoss: 1.0879\n",
      "Train Step: 20 (92.16%)  \tLoss: 1.0748\n",
      "Test set: Average loss: 1.1292, Accuracy: 6062/10000 (60.62%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 21 (00.00%)  \tLoss: 1.2546\n",
      "Train Step: 21 (46.08%)  \tLoss: 1.2246\n",
      "Train Step: 21 (92.16%)  \tLoss: 0.9321\n",
      "Test set: Average loss: 1.1356, Accuracy: 6063/10000 (60.63%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 22 (00.00%)  \tLoss: 0.8923\n",
      "Train Step: 22 (46.08%)  \tLoss: 1.0688\n",
      "Train Step: 22 (92.16%)  \tLoss: 0.9820\n",
      "Test set: Average loss: 1.1299, Accuracy: 6087/10000 (60.87%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 23 (00.00%)  \tLoss: 1.0620\n",
      "Train Step: 23 (46.08%)  \tLoss: 1.1863\n",
      "Train Step: 23 (92.16%)  \tLoss: 1.0886\n",
      "Test set: Average loss: 1.1272, Accuracy: 6131/10000 (61.31%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 24 (00.00%)  \tLoss: 0.9828\n",
      "Train Step: 24 (46.08%)  \tLoss: 1.1364\n",
      "Train Step: 24 (92.16%)  \tLoss: 1.0779\n",
      "Test set: Average loss: 1.1267, Accuracy: 6099/10000 (60.99%)\n",
      "\n",
      "Train Step: 25 (00.00%)  \tLoss: 1.1216\n",
      "Train Step: 25 (46.08%)  \tLoss: 0.9653\n",
      "Train Step: 25 (92.16%)  \tLoss: 0.8843\n",
      "Test set: Average loss: 1.1196, Accuracy: 6142/10000 (61.42%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 26 (00.00%)  \tLoss: 1.0863\n",
      "Train Step: 26 (46.08%)  \tLoss: 1.0270\n",
      "Train Step: 26 (92.16%)  \tLoss: 1.1329\n",
      "Test set: Average loss: 1.1201, Accuracy: 6120/10000 (61.20%)\n",
      "\n",
      "Train Step: 27 (00.00%)  \tLoss: 0.8636\n",
      "Train Step: 27 (46.08%)  \tLoss: 0.9946\n",
      "Train Step: 27 (92.16%)  \tLoss: 0.8580\n",
      "Test set: Average loss: 1.1105, Accuracy: 6130/10000 (61.30%)\n",
      "\n",
      "Train Step: 28 (00.00%)  \tLoss: 1.2565\n",
      "Train Step: 28 (46.08%)  \tLoss: 1.0228\n",
      "Train Step: 28 (92.16%)  \tLoss: 1.1083\n",
      "Test set: Average loss: 1.0998, Accuracy: 6211/10000 (62.11%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 29 (00.00%)  \tLoss: 1.0826\n",
      "Train Step: 29 (46.08%)  \tLoss: 1.0542\n",
      "Train Step: 29 (92.16%)  \tLoss: 1.0235\n",
      "Test set: Average loss: 1.1008, Accuracy: 6178/10000 (61.78%)\n",
      "\n",
      "Train Step: 30 (00.00%)  \tLoss: 1.0088\n",
      "Train Step: 30 (46.08%)  \tLoss: 0.9671\n",
      "Train Step: 30 (92.16%)  \tLoss: 1.1439\n",
      "Test set: Average loss: 1.0987, Accuracy: 6227/10000 (62.27%)\n",
      "discard previous state, best model state saved!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Code 3.4.3\n",
    "\n",
    "main(model=model, \n",
    "     train_loader=train_loader, \n",
    "     test_loader=test_loader, \n",
    "     loss_func=loss_function, \n",
    "     optimizer=optimizer, \n",
    "     n_step=STEP,\n",
    "     device=DEVICE,\n",
    "     save_path=\"cifar10_model.pt\", \n",
    "     print_step=PRINT_STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 더 큰 CNN 모델로 학습 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Train Step: 1 (00.00%)  \tLoss: 2.3042\n",
      "Train Step: 1 (46.08%)  \tLoss: 1.3663\n",
      "Train Step: 1 (92.16%)  \tLoss: 0.9663\n",
      "Test set: Average loss: 1.4098, Accuracy: 4909/10000 (49.09%)\n",
      "\n",
      "Train Step: 2 (00.00%)  \tLoss: 1.2599\n",
      "Train Step: 2 (46.08%)  \tLoss: 0.8084\n",
      "Train Step: 2 (92.16%)  \tLoss: 0.8922\n",
      "Test set: Average loss: 1.2616, Accuracy: 5540/10000 (55.40%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 3 (00.00%)  \tLoss: 0.9929\n",
      "Train Step: 3 (46.08%)  \tLoss: 0.7930\n",
      "Train Step: 3 (92.16%)  \tLoss: 0.8511\n",
      "Test set: Average loss: 0.9333, Accuracy: 6753/10000 (67.53%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 4 (00.00%)  \tLoss: 0.8435\n",
      "Train Step: 4 (46.08%)  \tLoss: 0.6593\n",
      "Train Step: 4 (92.16%)  \tLoss: 0.6612\n",
      "Test set: Average loss: 1.0638, Accuracy: 6280/10000 (62.80%)\n",
      "\n",
      "Train Step: 5 (00.00%)  \tLoss: 0.6862\n",
      "Train Step: 5 (46.08%)  \tLoss: 0.7007\n",
      "Train Step: 5 (92.16%)  \tLoss: 0.7449\n",
      "Test set: Average loss: 1.4279, Accuracy: 5617/10000 (56.17%)\n",
      "\n",
      "Train Step: 6 (00.00%)  \tLoss: 0.5583\n",
      "Train Step: 6 (46.08%)  \tLoss: 0.5905\n",
      "Train Step: 6 (92.16%)  \tLoss: 0.6041\n",
      "Test set: Average loss: 1.0431, Accuracy: 6537/10000 (65.37%)\n",
      "\n",
      "Train Step: 7 (00.00%)  \tLoss: 0.5164\n",
      "Train Step: 7 (46.08%)  \tLoss: 0.5675\n",
      "Train Step: 7 (92.16%)  \tLoss: 0.4531\n",
      "Test set: Average loss: 1.2820, Accuracy: 6121/10000 (61.21%)\n",
      "\n",
      "Train Step: 8 (00.00%)  \tLoss: 0.4346\n",
      "Train Step: 8 (46.08%)  \tLoss: 0.4037\n",
      "Train Step: 8 (92.16%)  \tLoss: 0.4135\n",
      "Test set: Average loss: 0.7541, Accuracy: 7472/10000 (74.72%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 9 (00.00%)  \tLoss: 0.3512\n",
      "Train Step: 9 (46.08%)  \tLoss: 0.3881\n",
      "Train Step: 9 (92.16%)  \tLoss: 0.4297\n",
      "Test set: Average loss: 0.8489, Accuracy: 7316/10000 (73.16%)\n",
      "\n",
      "Train Step: 10 (00.00%)  \tLoss: 0.3203\n",
      "Train Step: 10 (46.08%)  \tLoss: 0.2626\n",
      "Train Step: 10 (92.16%)  \tLoss: 0.3733\n",
      "Test set: Average loss: 0.8873, Accuracy: 7155/10000 (71.55%)\n",
      "\n",
      "Train Step: 11 (00.00%)  \tLoss: 0.4140\n",
      "Train Step: 11 (46.08%)  \tLoss: 0.2429\n",
      "Train Step: 11 (92.16%)  \tLoss: 0.5103\n",
      "Test set: Average loss: 0.8431, Accuracy: 7465/10000 (74.65%)\n",
      "\n",
      "Train Step: 12 (00.00%)  \tLoss: 0.1978\n",
      "Train Step: 12 (46.08%)  \tLoss: 0.2854\n",
      "Train Step: 12 (92.16%)  \tLoss: 0.2437\n",
      "Test set: Average loss: 1.1182, Accuracy: 6986/10000 (69.86%)\n",
      "\n",
      "Train Step: 13 (00.00%)  \tLoss: 0.1438\n",
      "Train Step: 13 (46.08%)  \tLoss: 0.2897\n",
      "Train Step: 13 (92.16%)  \tLoss: 0.2467\n",
      "Test set: Average loss: 1.2017, Accuracy: 6995/10000 (69.95%)\n",
      "\n",
      "Train Step: 14 (00.00%)  \tLoss: 0.1828\n",
      "Train Step: 14 (46.08%)  \tLoss: 0.2283\n",
      "Train Step: 14 (92.16%)  \tLoss: 0.1417\n",
      "Test set: Average loss: 0.9846, Accuracy: 7483/10000 (74.83%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 15 (00.00%)  \tLoss: 0.1616\n",
      "Train Step: 15 (46.08%)  \tLoss: 0.1800\n",
      "Train Step: 15 (92.16%)  \tLoss: 0.2518\n",
      "Test set: Average loss: 1.1665, Accuracy: 7211/10000 (72.11%)\n",
      "\n",
      "Train Step: 16 (00.00%)  \tLoss: 0.0977\n",
      "Train Step: 16 (46.08%)  \tLoss: 0.2667\n",
      "Train Step: 16 (92.16%)  \tLoss: 0.2777\n",
      "Test set: Average loss: 1.1102, Accuracy: 7419/10000 (74.19%)\n",
      "\n",
      "Train Step: 17 (00.00%)  \tLoss: 0.1700\n",
      "Train Step: 17 (46.08%)  \tLoss: 0.0890\n",
      "Train Step: 17 (92.16%)  \tLoss: 0.2048\n",
      "Test set: Average loss: 1.1149, Accuracy: 7475/10000 (74.75%)\n",
      "\n",
      "Train Step: 18 (00.00%)  \tLoss: 0.0781\n",
      "Train Step: 18 (46.08%)  \tLoss: 0.0850\n",
      "Train Step: 18 (92.16%)  \tLoss: 0.1142\n",
      "Test set: Average loss: 1.1453, Accuracy: 7398/10000 (73.98%)\n",
      "\n",
      "Train Step: 19 (00.00%)  \tLoss: 0.0987\n",
      "Train Step: 19 (46.08%)  \tLoss: 0.0608\n",
      "Train Step: 19 (92.16%)  \tLoss: 0.1673\n",
      "Test set: Average loss: 1.1330, Accuracy: 7452/10000 (74.52%)\n",
      "\n",
      "Train Step: 20 (00.00%)  \tLoss: 0.1004\n",
      "Train Step: 20 (46.08%)  \tLoss: 0.1262\n",
      "Train Step: 20 (92.16%)  \tLoss: 0.1832\n",
      "Test set: Average loss: 1.3659, Accuracy: 7263/10000 (72.63%)\n",
      "\n",
      "Train Step: 21 (00.00%)  \tLoss: 0.0738\n",
      "Train Step: 21 (46.08%)  \tLoss: 0.0632\n",
      "Train Step: 21 (92.16%)  \tLoss: 0.0719\n",
      "Test set: Average loss: 1.3557, Accuracy: 7253/10000 (72.53%)\n",
      "\n",
      "Train Step: 22 (00.00%)  \tLoss: 0.0463\n",
      "Train Step: 22 (46.08%)  \tLoss: 0.0897\n",
      "Train Step: 22 (92.16%)  \tLoss: 0.2793\n",
      "Test set: Average loss: 1.6192, Accuracy: 6765/10000 (67.65%)\n",
      "\n",
      "Train Step: 23 (00.00%)  \tLoss: 0.1236\n",
      "Train Step: 23 (46.08%)  \tLoss: 0.0630\n",
      "Train Step: 23 (92.16%)  \tLoss: 0.0690\n",
      "Test set: Average loss: 1.7452, Accuracy: 6960/10000 (69.60%)\n",
      "\n",
      "Train Step: 24 (00.00%)  \tLoss: 0.1178\n",
      "Train Step: 24 (46.08%)  \tLoss: 0.0439\n",
      "Train Step: 24 (92.16%)  \tLoss: 0.0573\n",
      "Test set: Average loss: 1.3893, Accuracy: 7292/10000 (72.92%)\n",
      "\n",
      "Train Step: 25 (00.00%)  \tLoss: 0.1293\n",
      "Train Step: 25 (46.08%)  \tLoss: 0.0801\n",
      "Train Step: 25 (92.16%)  \tLoss: 0.0848\n",
      "Test set: Average loss: 1.3634, Accuracy: 7459/10000 (74.59%)\n",
      "\n",
      "Train Step: 26 (00.00%)  \tLoss: 0.0628\n",
      "Train Step: 26 (46.08%)  \tLoss: 0.0119\n",
      "Train Step: 26 (92.16%)  \tLoss: 0.1276\n",
      "Test set: Average loss: 1.3360, Accuracy: 7565/10000 (75.65%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 27 (00.00%)  \tLoss: 0.0689\n",
      "Train Step: 27 (46.08%)  \tLoss: 0.0944\n",
      "Train Step: 27 (92.16%)  \tLoss: 0.0920\n",
      "Test set: Average loss: 1.4345, Accuracy: 7403/10000 (74.03%)\n",
      "\n",
      "Train Step: 28 (00.00%)  \tLoss: 0.0395\n",
      "Train Step: 28 (46.08%)  \tLoss: 0.0445\n",
      "Train Step: 28 (92.16%)  \tLoss: 0.1091\n",
      "Test set: Average loss: 1.6097, Accuracy: 7293/10000 (72.93%)\n",
      "\n",
      "Train Step: 29 (00.00%)  \tLoss: 0.0397\n",
      "Train Step: 29 (46.08%)  \tLoss: 0.0567\n",
      "Train Step: 29 (92.16%)  \tLoss: 0.0842\n",
      "Test set: Average loss: 1.5195, Accuracy: 7369/10000 (73.69%)\n",
      "\n",
      "Train Step: 30 (00.00%)  \tLoss: 0.1203\n",
      "Train Step: 30 (46.08%)  \tLoss: 0.0406\n",
      "Train Step: 30 (92.16%)  \tLoss: 0.1597\n",
      "Test set: Average loss: 1.5329, Accuracy: 7336/10000 (73.36%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Code 3.4.4\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "# 3.2.8 장에서 정의한 훈련 및 테스트 함수를 불러온다.\n",
    "from train_utils import train, test, main\n",
    "# custom_cnn 의 CNN 모델을 불러온다.\n",
    "from custom_cnn import CNN\n",
    "\n",
    "# 데이터 셋 불러오기\n",
    "train_dataset = datasets.CIFAR10('./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.CIFAR10('./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "# 환경 변수 설정\n",
    "BATCH = 128  # 미니배치크기\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'  # 디바이스\n",
    "STEP = 30  # 총 반복스텝\n",
    "PRINT_STEP = 180  # 경과 print 기간\n",
    "# 모델 환경 변수 설정\n",
    "config = [\n",
    "    ('ch_in', 3), ('n_in', 32),\n",
    "    ('conv1', (32, 7, 1, 1)), ('pool1', 2), \n",
    "    ('conv2', (64, 5, 1, 1)), ('pool2', 2), \n",
    "    ('conv3', (128, 3, 1, 0)), ('pool3', 2),\n",
    "    ('fc', (250, 50, 10))\n",
    "    ]\n",
    "\n",
    "# 데이터로더 선언\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH, shuffle=True)\n",
    "\n",
    "# 모델 선언\n",
    "torch.manual_seed(70)\n",
    "model = CNN(config).to(DEVICE)\n",
    "# 손실함수 선언\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "# 옵티마이저 선언\n",
    "optimizer = optim.Adam(model.parameters()) \n",
    "\n",
    "main(model=model, \n",
    "     train_loader=train_loader, \n",
    "     test_loader=test_loader, \n",
    "     loss_func=loss_function, \n",
    "     optimizer=optimizer, \n",
    "     n_step=STEP,\n",
    "     device=DEVICE,\n",
    "     save_path=\"cifar10_model.pt\", \n",
    "     print_step=PRINT_STEP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 클래스 별로 정확도 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plane \t: 73.90%\n",
      "car \t: 87.20%\n",
      "bird \t: 64.80%\n",
      "cat \t: 64.10%\n",
      "deer \t: 74.10%\n",
      "dog \t: 66.10%\n",
      "frog \t: 77.20%\n",
      "horse \t: 77.60%\n",
      "ship \t: 86.00%\n",
      "truck \t: 82.60%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from custom_cnn import CNN\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# 데이터 불러오기\n",
    "test_dataset = datasets.CIFAR10('./data', train=False, transform=transforms.ToTensor())\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "BATCH = 128\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH, shuffle=True)\n",
    "\n",
    "# config\n",
    "config = [\n",
    "    ('ch_in', 3), ('n_in', 32),\n",
    "    ('conv1', (32, 7, 1, 1)), ('pool1', 2), \n",
    "    ('conv2', (64, 5, 1, 1)), ('pool2', 2), \n",
    "    ('conv3', (128, 3, 1, 0)), ('pool3', 2),\n",
    "    ('fc', (250, 50, 10))\n",
    "    ]\n",
    "\n",
    "model = CNN(config).to(DEVICE)\n",
    "# 모델 불러오기\n",
    "model_path = \"./cifar10_model.pt\"\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# class 별로 맞춘 개수 계산하는 함수\n",
    "def cal_correct_by_class(model, test_loader, device):\n",
    "    total = torch.zeros(10)\n",
    "    correct = torch.zeros(10)\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data.to(device))\n",
    "            pred = output.cpu().softmax(1).argmax(1)\n",
    "            correct_idx = pred.masked_select((pred == target))\n",
    "            correct += torch.zeros(correct_idx.size(0), 10).scatter(1, correct_idx.view(-1, 1), 1).sum(0)\n",
    "            total += torch.zeros(target.size(0), 10).scatter(1, target.view(-1, 1), 1).sum(0)\n",
    "            \n",
    "    percentage = correct/total\n",
    "\n",
    "    return percentage\n",
    "\n",
    "percentage = cal_correct_by_class(model, test_loader, device=DEVICE)\n",
    "for cls_name, percent in zip(classes, percentage):\n",
    "    print(\"{} \\t: {:05.2f}%\".format(cls_name, percent*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(torchenv)",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
