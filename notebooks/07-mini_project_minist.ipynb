{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Project: Deep Learning with Mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# matplotlib 패키지 결과물을 노트북을 실행한 브라우저 안에 보일 수 있도록 하는 명령어다. \n",
    "%matplotlib inline\n",
    "# numpy 와 pytorch 패키지 불러오기 \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# 데이터로더 및 mnist 가 내장 되어있는 torchvision 패키지에서 데이터셋 불러오기\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# 손글씨를 써볼 수 있는 GUI 프로그램\n",
    "from drawing import Drawing\n",
    "# 그림 시각화 처리를 위한 패키지\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def drawing_custom_number(preprocess, filepath=\"./figs\", return_img=True):\n",
    "    \"\"\"손글씨 입력 GUI 미니 프로그램\"\"\"\n",
    "    if (not os.path.isdir(\"figs\")) and (filepath == \"./figs\"):\n",
    "        os.mkdir(\"figs\")\n",
    "    draw = Drawing()\n",
    "    draw.main(preprocess=preprocess, filepath=filepath)\n",
    "    img = Image.open(draw.file)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    if return_img:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0\n",
      "Size of Image: (28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(70)\n",
    "\n",
    "# 데이터셋 정의하기\n",
    "train_dataset = datasets.MNIST(root='./data',  # 데이터 경로\n",
    "                               train=True,  # 훈련데이터의 여부\n",
    "                               download=True,  # 기존에 없다면 root 경로에 다운로드를 받게 된다.\n",
    "                               transform=transforms.ToTensor())  # 텐서로 바꾸는 전처리를 한다.\n",
    "test_dataset = datasets.MNIST(root='./data', # 데이터 경로\n",
    "                              train=False,  # 훈련데이터의 여부\n",
    "                              transform=transforms.ToTensor())  # 텐서로 바꾸는 전처리를 한다.\n",
    "\n",
    "# 데이터 살펴보기: 훈련데이터 중 임의의 데이터를 골라서 보여준다\n",
    "idx = torch.randint(0, len(train_dataset), (1,)).item()\n",
    "random_image = train_dataset[idx][0].squeeze().numpy()\n",
    "target_num = train_dataset[idx][1]\n",
    "print(\"Target: {}\".format(target_num))\n",
    "print(\"Size of Image: {}\".format(random_image.shape))\n",
    "plt.imshow(random_image, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미니배치크기\n",
    "BATCH = 64\n",
    "# 디바이스 설정: cuda 사용할지 cpu 사용할지\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# 총 스텝 크기\n",
    "STEP = 10\n",
    "\n",
    "# 훈련 데이터로더 선언\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH, \n",
    "                          shuffle=True)\n",
    "# 테스트 데이터 로더 설정\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH, \n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for (data, target) in train_loader:\n",
    "    print(data.size(), target.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.flatten = lambda x: x.view(x.size(0), -1)\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 선언\n",
    "model = Net(input_size=28*28, hidden_size=100, output_size=10).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 89610\n"
     ]
    }
   ],
   "source": [
    "# 손실함수와 옵티마이저 선언\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# 매개변수 개수 확인하기\n",
    "num_params = 0\n",
    "for params in model.parameters():\n",
    "    num_params += params.view(-1).size(0)\n",
    "print(\"Total number of parameters: {}\".format(num_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, loss_func, optimizer, step, device, print_step=200):\n",
    "    \"\"\"train function: 1 스텝 동안 발생하는 학습과정\"\"\"\n",
    "    # 모델에게 훈련단계이라고 선언함\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # 입력과 타겟 텐서에 GPU 를 사용여부 전달\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # 경사 초기화\n",
    "        model.zero_grad()\n",
    "        # 순방향 전파\n",
    "        output = model(data)\n",
    "        # 손실값 계산\n",
    "        loss = loss_func(output, target)\n",
    "        # 역방향 전파\n",
    "        loss.backward()\n",
    "        # 매개변수 업데이트\n",
    "        optimizer.step()\n",
    "        # 중간 과정 print\n",
    "        if batch_idx % print_step == 0:\n",
    "            print('Train Step: {} ({:05.2f}%)  \\tLoss: {:.4f}'.format(\n",
    "                step, 100.*(batch_idx*train_loader.batch_size)/len(train_loader.dataset), \n",
    "                loss.item()))\n",
    "            \n",
    "def test(model, test_loader, loss_func, device):\n",
    "    \"\"\"test function\"\"\"\n",
    "    # 모델에게 평가단계이라고 선언함\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            # 입력과 타겟 텐서에 GPU 를 사용여부 전달\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # 순방향전파\n",
    "            output = model(data)\n",
    "            # 손실값 계산(합)\n",
    "            test_loss += loss_func(output, target, reduction=\"sum\").item()\n",
    "            # 예측 값에 해당하는 클래스 번호 반환\n",
    "            pred = output.softmax(1).argmax(dim=1, keepdim=True)\n",
    "            # 정확하게 예측한 개수를 기록한다\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = correct / len(test_loader.dataset)\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:05.2f}%)'.format(\n",
    "        test_loss, correct, len(test_loader.dataset), 100. * test_acc))\n",
    "    return test_loss, test_acc\n",
    "\n",
    "def main(model, train_loader, test_loader, loss_func, optimizer, n_step, device, save_path=None, print_step=200):\n",
    "    \"\"\"메인 학습 함수\"\"\"\n",
    "    test_accs = []\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for step in range(1, n_step+1):\n",
    "        # 훈련 단계\n",
    "        train(model, train_loader, loss_func, optimizer, \n",
    "              step=step, device=device, print_step=print_step)\n",
    "        # 평가 단계\n",
    "        test_loss, test_acc = test(model, test_loader, \n",
    "                                   loss_func=F.cross_entropy, \n",
    "                                   device=device)\n",
    "        # 테스트 정확도 기록\n",
    "        test_accs.append(test_acc)\n",
    "        # 모델 최적의 매개변수값을 저장할지 결정하고 기록한다.\n",
    "        if len(test_accs) >= 2:\n",
    "            if test_acc >= best_acc:\n",
    "                best_acc = test_acc\n",
    "                best_state_dict = model.state_dict()\n",
    "                print(\"discard previous state, best model state saved!\")\n",
    "        print(\"\")\n",
    "\n",
    "    # 매개변수 값 저장하기\n",
    "    if save_path is not None:\n",
    "        torch.save(best_state_dict, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Step: 1 (00.00%)  \tLoss: 2.3059\n",
      "Train Step: 1 (21.33%)  \tLoss: 0.3634\n",
      "Train Step: 1 (42.67%)  \tLoss: 0.3047\n",
      "Train Step: 1 (64.00%)  \tLoss: 0.2676\n",
      "Train Step: 1 (85.33%)  \tLoss: 0.1025\n",
      "Test set: Average loss: 0.1930, Accuracy: 9432/10000 (94.32%)\n",
      "\n",
      "\n",
      "Train Step: 2 (00.00%)  \tLoss: 0.1612\n",
      "Train Step: 2 (21.33%)  \tLoss: 0.1680\n",
      "Train Step: 2 (42.67%)  \tLoss: 0.4351\n",
      "Train Step: 2 (64.00%)  \tLoss: 0.1838\n",
      "Train Step: 2 (85.33%)  \tLoss: 0.1939\n",
      "Test set: Average loss: 0.1386, Accuracy: 9598/10000 (95.98%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "\n",
      "Train Step: 3 (00.00%)  \tLoss: 0.2025\n",
      "Train Step: 3 (21.33%)  \tLoss: 0.0545\n",
      "Train Step: 3 (42.67%)  \tLoss: 0.2155\n",
      "Train Step: 3 (64.00%)  \tLoss: 0.0734\n",
      "Train Step: 3 (85.33%)  \tLoss: 0.0663\n",
      "Test set: Average loss: 0.1136, Accuracy: 9645/10000 (96.45%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "\n",
      "Train Step: 4 (00.00%)  \tLoss: 0.1129\n",
      "Train Step: 4 (21.33%)  \tLoss: 0.0490\n",
      "Train Step: 4 (42.67%)  \tLoss: 0.1996\n",
      "Train Step: 4 (64.00%)  \tLoss: 0.2103\n",
      "Train Step: 4 (85.33%)  \tLoss: 0.0263\n",
      "Test set: Average loss: 0.0950, Accuracy: 9713/10000 (97.13%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "\n",
      "Train Step: 5 (00.00%)  \tLoss: 0.0649\n",
      "Train Step: 5 (21.33%)  \tLoss: 0.0862\n",
      "Train Step: 5 (42.67%)  \tLoss: 0.0092\n",
      "Train Step: 5 (64.00%)  \tLoss: 0.0281\n",
      "Train Step: 5 (85.33%)  \tLoss: 0.0435\n",
      "Test set: Average loss: 0.0896, Accuracy: 9740/10000 (97.40%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "\n",
      "Train Step: 6 (00.00%)  \tLoss: 0.0464\n",
      "Train Step: 6 (21.33%)  \tLoss: 0.0252\n",
      "Train Step: 6 (42.67%)  \tLoss: 0.0349\n",
      "Train Step: 6 (64.00%)  \tLoss: 0.0141\n",
      "Train Step: 6 (85.33%)  \tLoss: 0.0282\n",
      "Test set: Average loss: 0.0969, Accuracy: 9723/10000 (97.23%)\n",
      "\n",
      "\n",
      "Train Step: 7 (00.00%)  \tLoss: 0.0328\n",
      "Train Step: 7 (21.33%)  \tLoss: 0.0237\n",
      "Train Step: 7 (42.67%)  \tLoss: 0.1593\n",
      "Train Step: 7 (64.00%)  \tLoss: 0.0827\n",
      "Train Step: 7 (85.33%)  \tLoss: 0.0461\n",
      "Test set: Average loss: 0.0800, Accuracy: 9751/10000 (97.51%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "\n",
      "Train Step: 8 (00.00%)  \tLoss: 0.0384\n",
      "Train Step: 8 (21.33%)  \tLoss: 0.0217\n",
      "Train Step: 8 (42.67%)  \tLoss: 0.0187\n",
      "Train Step: 8 (64.00%)  \tLoss: 0.0112\n",
      "Train Step: 8 (85.33%)  \tLoss: 0.1033\n",
      "Test set: Average loss: 0.0986, Accuracy: 9726/10000 (97.26%)\n",
      "\n",
      "\n",
      "Train Step: 9 (00.00%)  \tLoss: 0.0050\n",
      "Train Step: 9 (21.33%)  \tLoss: 0.0055\n",
      "Train Step: 9 (42.67%)  \tLoss: 0.0549\n",
      "Train Step: 9 (64.00%)  \tLoss: 0.0304\n",
      "Train Step: 9 (85.33%)  \tLoss: 0.0609\n",
      "Test set: Average loss: 0.0888, Accuracy: 9763/10000 (97.63%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "\n",
      "Train Step: 10 (00.00%)  \tLoss: 0.0220\n",
      "Train Step: 10 (21.33%)  \tLoss: 0.0111\n",
      "Train Step: 10 (42.67%)  \tLoss: 0.0203\n",
      "Train Step: 10 (64.00%)  \tLoss: 0.0005\n",
      "Train Step: 10 (85.33%)  \tLoss: 0.0166\n",
      "Test set: Average loss: 0.0868, Accuracy: 9772/10000 (97.72%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main(model=model, \n",
    "     train_loader=train_loader, \n",
    "     test_loader=test_loader, \n",
    "     loss_func=loss_function, \n",
    "     optimizer=optimizer, \n",
    "     n_step=STEP,\n",
    "     device=DEIVCE,\n",
    "     save_path=\"mnist_model.pt\", \n",
    "     print_step=PRINT_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved ./figs/number.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = drawing_custom_number(preprocess=True, return_img=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted number is 7.\n"
     ]
    }
   ],
   "source": [
    "# 내가 그린 이미지 테스트\n",
    "# 이미지를 (1, 28, 28) 크기의 텐서로 바꿔준다\n",
    "test_input = torch.Tensor(np.array(img)).unsqueeze(0).to(DEVICE)\n",
    "pred = model(test_input)\n",
    "print(\"Predicted number is {}.\".format(pred.softmax(1).argmax().item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(torchenv)",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
